import streamlit as st
import google.generativeai as genai

# --- CONFIGURA√á√ÉO DA P√ÅGINA ---
st.set_page_config(page_title="Nice Le√£o Ateli√™", page_icon="ü™°")

# Estilo Verde Oliva
st.markdown("""
    <style>
    .stApp { background-color: #fcfdf9; }
    h1, h2, h3 { color: #556b2f !important; font-family: 'Georgia', serif; }
    .stChatInputContainer { padding-bottom: 20px; }
    </style>
    """, unsafe_allow_html=True)

# --- CONFIGURA√á√ÉO DA CHAVE ---
minha_chave = st.secrets.get("GOOGLE_API_KEY")

# --- CONTE√öDO DO ATELI√ä ---
st.title("ü™° Nice Le√£o Ateli√™")
st.subheader("Presentes Personalizados e Costura Criativa")

# Instru√ß√µes para a IA
PROMPT_SISTEMA = """
Voc√™ √© o assistente virtual do 'Nice Le√£o Ateli√™'.
Seu tom de voz: Acolhedor, artesanal, educado e criativo.

PRODUTOS:
- Canecas (Brancas, Coloridas, X√≠caras).
- Kits: Caneca/X√≠cara + Bag de Algod√£o + Mug Rug Dupla Face.
- Copos de Vidro Summer.
- N√©cessaires de tecido (P, M, G) e N√©cessaire toalhinha.
- Porta livros, Porta documentos infantil, Porta joias em tecido.
- Kit Caneca Box com infusor.

REGRAS:
1. Sempre pergunte o NOME do cliente no in√≠cio.
2. Pe√ßa o CEP para que a Nice possa calcular o frete e o prazo.
3. Se o cliente perguntar pre√ßo e voc√™ n√£o tiver certeza, diga que a Nice enviar√° o or√ßamento detalhado.
"""

if minha_chave:
    try:
        genai.configure(api_key=minha_chave)
        
        # USANDO O MODELO QUE FUNCIONOU NO SEU TESTE
        model = genai.GenerativeModel('models/gemini-2.5-flash')

        if "messages" not in st.session_state:
            st.session_state.messages = []

        # Exibir hist√≥rico
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        # Chat
        if prompt := st.chat_input("Ol√°! Como posso te ajudar?"):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            # Resposta com o contexto do Ateli√™
            contexto = f"{PROMPT_SISTEMA}\n\nPergunta do cliente: {prompt}"
            response = model.generate_content(contexto)
            
            st.session_state.messages.append({"role": "assistant", "content": response.text})
            with st.chat_message("assistant"):
                st.markdown(response.text)
                
    except Exception as e:
        st.error(f"Erro ao conversar com o assistente: {e}")
else:
    st.info("üåø Bem-vindo! Por favor, configure a chave API nos Secrets do Streamlit.")
