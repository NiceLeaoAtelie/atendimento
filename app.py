import streamlit as st
import google.generativeai as genai

# --- CONFIGURA√á√ÉO DA P√ÅGINA ---
st.set_page_config(page_title="Nice Le√£o Ateli√™", page_icon="ü™°")

# Estilo Verde Oliva
st.markdown("""
    <style>
    .stApp { background-color: #fcfdf9; }
    h1, h2, h3 { color: #556b2f !important; font-family: 'Georgia', serif; }
    </style>
    """, unsafe_allow_html=True)

# --- CONFIGURA√á√ÉO DA CHAVE ---
minha_chave = st.secrets.get("GOOGLE_API_KEY")

if not minha_chave:
    with st.sidebar:
        st.warning("Chave n√£o encontrada nos Secrets.")
        minha_chave = st.text_input("Insira sua API Key manualmente:", type="password")

# --- CONTE√öDO DO ATELI√ä ---
st.title("ü™° Nice Le√£o Ateli√™")
st.write("Assistente virtual de presentes personalizados.")

PROMPT_SISTEMA = """
Voc√™ √© o assistente do Nice Le√£o Ateli√™. Especialista em Costura Criativa e Sublima√ß√£o.
PRODUTOS: Canecas, Kits (Caneca+Bag+Mug Rug), Copo Summer, N√©cessaires P/M/G, Porta Livros/Documentos.
OBJETIVO: Ser acolhedor, perguntar o NOME do cliente e pedir o CEP para or√ßamento.
Responda sempre em Portugu√™s do Brasil.
"""

if minha_chave:
    try:
        # Configura√ß√£o for√ßada da API
        genai.configure(api_key=minha_chave)
        
        # Usando o nome completo do modelo para evitar o erro 404
        # 'models/gemini-1.5-flash' √© o endere√ßo est√°vel oficial
        model = genai.GenerativeModel(model_name='models/gemini-1.5-flash')

        if "messages" not in st.session_state:
            st.session_state.messages = []

        # Exibir mensagens
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        if prompt := st.chat_input("Como a Nice pode te ajudar hoje?"):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            # Gerar resposta
            contexto = f"{PROMPT_SISTEMA}\n\nPergunta do cliente: {prompt}"
            
            # Chamada simplificada para garantir compatibilidade
            response = model.generate_content(contexto)
            
            st.session_state.messages.append({"role": "assistant", "content": response.text})
            with st.chat_message("assistant"):
                st.markdown(response.text)
                
    except Exception as e:
        # Se o erro 404 persistir, ele mostrar√° uma mensagem amig√°vel
        st.error(f"Erro de conex√£o com o modelo: {e}")
        st.info("Dica: Verifique se sua chave no Google AI Studio est√° ativa.")
else:
    st.info("üåø Por favor, configure a chave API nos Secrets do Streamlit para come√ßar.")
